{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "data = [\"Hello mehmet how are you today\",\"I'm fine and you\", \"Today it is rainy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "from typing import List, Union, Tuple\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SentenceTransformer('xlm-r-distilroberta-base-paraphrase-v1')\n",
    "# embeddings = model.encode(list_data, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(docs: List[str],\n",
    "                     keyphrase_ngram_range: Tuple[int, int] = (1, 1),\n",
    "                     top_n: int = 5,\n",
    "                     min_df: int = 1,\n",
    "                     diversity: float = 0.5,\n",
    "                     nr_candidates: int = 20,\n",
    "                     vectorizer: CountVectorizer = None):\n",
    "\n",
    "        return _extract_keywords_multiple_docs(docs,\n",
    "                                               keyphrase_ngram_range,\n",
    "                                               stop_words,\n",
    "                                               top_n,\n",
    "                                               min_df,\n",
    "                                               vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_keywords_multiple_docs(docs: List[str],\n",
    "                                    keyphrase_ngram_range: Tuple[int, int] = (1, 1),\n",
    "                                    top_n: int = 5,\n",
    "                                    min_df: int = 1,\n",
    "                                    vectorizer: CountVectorizer = None):\n",
    "\n",
    "    # Extract words\n",
    "    global count\n",
    "    if vectorizer:\n",
    "        count = vectorizer.fit(docs)\n",
    "    else:\n",
    "        count = CountVectorizer().fit(docs)\n",
    "    global words\n",
    "    global df\n",
    "    words = count.get_feature_names()\n",
    "    df = count.transform(docs)\n",
    "\n",
    "    # Extract embeddings\n",
    "    global word_embeddings\n",
    "    global doc_embeddings\n",
    "    word_embeddings = _extract_embeddings(words)\n",
    "    doc_embeddings = _extract_embeddings(docs)\n",
    "    # word_embeddings = self.model.encode(words, show_progress_bar=True)\n",
    "    # doc_embeddings = self.model.encode(docs, show_progress_bar=True)\n",
    "    global doc_word_embeddings\n",
    "    global distances\n",
    "    global doc_keywords\n",
    "    # Extract keywords\n",
    "    global docss\n",
    "    docss = docs\n",
    "    keywords = []\n",
    "    for index, doc in enumerate(docs):\n",
    "        doc_words = [words[i] for i in df[index].nonzero()[1]]\n",
    "        if doc_words:\n",
    "            doc_word_embeddings = np.array([word_embeddings[i] for i in df[index].nonzero()[1]])\n",
    "            distances = cosine_similarity([doc_embeddings[index]], doc_word_embeddings)[0]\n",
    "            doc_keywords = [(doc_words[i], round(float(distances[i]), 4)) for i in distances.argsort()[-top_n:]]\n",
    "            keywords.append(doc_keywords[::-1])\n",
    "        else:\n",
    "            keywords.append([\"None Found\"])\n",
    "\n",
    "    return keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_embeddings(documents: Union[List[str], str]) -> np.ndarray:\n",
    "    \n",
    "    embeddings = model.encode(documents)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hello', 0.4542), ('mehmet', 0.3992), ('today', 0.3238), ('you', 0.3041), ('how', 0.2213)]\n",
      "[('fine', 0.6716), ('you', 0.4057), ('and', 0.2061)]\n",
      "[('rainy', 0.7416), ('today', 0.4608), ('it', 0.2287), ('is', 0.2111)]\n"
     ]
    }
   ],
   "source": [
    "keys = _extract_keywords_multiple_docs(data)\n",
    "for i in keys:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and',\n",
       " 'are',\n",
       " 'fine',\n",
       " 'hello',\n",
       " 'how',\n",
       " 'is',\n",
       " 'it',\n",
       " 'mehmet',\n",
       " 'rainy',\n",
       " 'today',\n",
       " 'you']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.12196334e-01, -4.97781374e-02,  2.29725957e-01, -7.49675259e-02,\n",
       "       -3.62224013e-01, -2.27448389e-01, -4.69431549e-01,  4.40572262e-01,\n",
       "       -5.74928112e-02, -9.71604884e-02,  1.10986583e-01, -4.09315675e-01,\n",
       "        7.44651556e-02, -2.84056693e-01,  4.51938391e-01, -3.80099893e-01,\n",
       "        1.16217948e-01, -2.37163141e-01, -2.73544401e-01, -4.31471854e-01,\n",
       "       -3.63283068e-01, -4.36051637e-01,  2.45205715e-01,  1.86396196e-01,\n",
       "        1.19629897e-01, -6.53559938e-02,  3.23349953e-01,  5.46111345e-01,\n",
       "        1.30392253e-01,  2.32021913e-01, -5.19764833e-02,  4.63346904e-03,\n",
       "       -3.51227149e-02, -8.32454488e-02, -1.27970248e-01, -1.46831349e-02,\n",
       "        3.59459728e-01, -1.28858507e-01, -1.57206565e-01,  1.05993003e-02,\n",
       "       -3.31086546e-01, -9.55372229e-02, -3.01532652e-02,  1.36525407e-01,\n",
       "        1.43311424e-02,  1.77170038e-01, -1.33415341e-01, -9.87558886e-02,\n",
       "        3.20549123e-02, -2.50094235e-02,  2.85693377e-01,  8.56442004e-03,\n",
       "        1.74827412e-01,  3.30362767e-01, -4.39175695e-01, -1.15609579e-01,\n",
       "        2.05409452e-01, -1.76517293e-01, -1.25371024e-01,  1.94437101e-01,\n",
       "       -7.62186199e-02, -4.65396166e-01,  1.90206900e-01,  2.23512128e-01,\n",
       "        3.69203500e-02,  9.91773605e-02, -2.50876456e-01,  1.62688300e-01,\n",
       "       -1.39988894e-02,  2.52064466e-01,  9.31433216e-02,  1.06545903e-01,\n",
       "        2.11993322e-01, -7.08022043e-02, -1.34602904e-01,  2.56439805e-01,\n",
       "       -1.27393484e-01,  3.99660200e-01, -5.36098098e-03, -3.75537544e-01,\n",
       "        2.56402165e-01,  5.17780371e-02, -2.04876021e-01,  1.88248262e-01,\n",
       "        3.38753462e-01, -9.82750878e-02,  2.15155900e-01, -1.04485542e-01,\n",
       "        9.44168046e-02, -9.79557410e-02,  5.81550598e-02, -1.99001580e-02,\n",
       "       -1.67569354e-01,  2.11861774e-01,  3.37540150e-01,  1.88725188e-01,\n",
       "       -9.30591393e-03, -5.84624708e-01,  5.15424050e-02, -4.47533518e-01,\n",
       "       -3.82383078e-01,  2.72192508e-01,  2.74908870e-01,  2.05437303e-01,\n",
       "        1.19505070e-01,  4.16249901e-01, -7.95427188e-02,  1.34156585e-01,\n",
       "        1.22045062e-01, -1.14349008e-01,  4.87536080e-02,  4.59923595e-01,\n",
       "       -1.46502167e-01, -1.15901849e-03,  3.90120625e-01, -3.57735127e-01,\n",
       "       -1.70623381e-02,  2.14315698e-01,  1.69241086e-01, -2.34075293e-01,\n",
       "        3.49573821e-01,  7.92811885e-02, -6.96539953e-02,  3.52499574e-01,\n",
       "       -2.54649967e-01,  1.36293933e-01,  7.99189787e-03, -1.56348348e-02,\n",
       "        8.81820451e-03,  3.24182123e-01,  1.38594374e-01, -6.38727963e-01,\n",
       "        1.88990906e-02,  1.66156486e-01, -8.39297548e-02,  1.76204190e-01,\n",
       "        1.45402566e-01, -1.17376000e-01, -3.41868890e-03,  8.17777440e-02,\n",
       "        1.34580091e-01,  1.27109349e-01, -1.37703016e-01, -2.69907471e-02,\n",
       "        2.13176444e-01, -3.43191266e-01,  3.12870830e-01,  8.22983403e-03,\n",
       "        3.94734144e-01, -1.90227285e-01, -3.01733613e-01, -3.90117407e-01,\n",
       "       -1.65712520e-01, -4.74831089e-04, -1.31245047e-01,  2.94285804e-01,\n",
       "        2.95602769e-01, -1.66619018e-01,  2.11083312e-02,  2.34517887e-01,\n",
       "        2.72760600e-01,  1.11862935e-01, -1.33038759e-01, -2.37652063e-02,\n",
       "        9.43315849e-02,  1.07193656e-01,  2.86844760e-01,  2.02991500e-01,\n",
       "        1.66219130e-01, -1.57900274e-01, -1.33108152e-02, -9.24087986e-02,\n",
       "        1.59522727e-01, -3.86765711e-02, -2.13606462e-01,  2.69556135e-01,\n",
       "        6.71107462e-03, -6.96553430e-03, -2.80115515e-01,  1.53607830e-01,\n",
       "        1.26306996e-01,  5.03994524e-01,  9.11019444e-02,  7.69705176e-02,\n",
       "       -1.53446689e-01,  1.94593832e-01,  9.74293575e-02, -3.86783928e-01,\n",
       "        2.05497816e-01, -3.91053796e-01,  2.34152913e-01, -2.29091048e-02,\n",
       "       -1.09021246e-01, -5.42706018e-03,  4.12832111e-01, -3.60430121e-01,\n",
       "        1.14633143e-01,  3.78441453e-01,  2.38144949e-01,  2.56203502e-01,\n",
       "       -3.28246243e-02, -3.14486712e-01,  3.85044813e-02,  5.98493516e-02,\n",
       "        2.64447778e-01,  1.71132639e-01,  6.79147840e-02, -5.49672246e-02,\n",
       "        3.29177022e-01, -2.50328034e-01,  1.96115568e-01,  3.86334032e-01,\n",
       "       -1.17104508e-01, -1.04736723e-01, -1.68792725e-01,  2.45867923e-01,\n",
       "        1.56290364e-02, -7.98224434e-02, -3.99384528e-01, -3.34234208e-01,\n",
       "        1.82782575e-01, -7.55576566e-02,  8.97243321e-02, -1.79433033e-01,\n",
       "       -2.26018324e-01,  2.30933592e-01,  1.59804374e-02, -3.75172585e-01,\n",
       "       -2.31180504e-01, -5.83128631e-02,  1.96311355e-01, -1.12206377e-01,\n",
       "        6.79914579e-02,  9.85079110e-02,  2.90440112e-01,  8.19817409e-02,\n",
       "       -3.02706420e-01,  1.79748252e-01, -1.07791424e-01, -2.41941974e-01,\n",
       "        3.61900717e-01,  2.68153042e-01, -1.27898470e-01,  3.61268431e-01,\n",
       "       -3.06998044e-01, -1.91092685e-01, -5.79452030e-02, -3.48303691e-02,\n",
       "       -2.72817880e-01, -3.74342091e-02,  3.65890712e-02, -2.43802503e-01,\n",
       "        1.47768810e-01,  2.12435678e-01,  2.33084083e-01, -2.08675623e-01,\n",
       "        6.54310510e-02, -1.50633052e-01,  2.53933907e-01,  5.12478113e-01,\n",
       "        2.25792482e-01, -4.32460606e-02,  2.12723956e-01, -5.83292656e-02,\n",
       "       -2.87184678e-03,  2.06400845e-02, -3.32974792e-01,  1.40852854e-01,\n",
       "        3.57973367e-01, -8.02458674e-02,  3.01077217e-01,  3.80130917e-01,\n",
       "       -3.88431460e-01, -5.92074776e-03, -3.06381792e-01, -3.89296293e-01,\n",
       "       -8.83123800e-02,  4.39524084e-01, -4.12938237e-01,  1.24379575e-01,\n",
       "       -2.18527615e-02,  4.46155816e-01,  9.31526423e-02,  2.87766546e-01,\n",
       "        1.49865821e-01,  6.05922751e-02,  2.07173347e-01,  2.36723825e-01,\n",
       "       -5.40816188e-02, -1.67176053e-01, -3.99589986e-01,  1.60532773e-01,\n",
       "       -1.93218887e-02, -3.89168747e-02,  3.71309258e-02, -3.03024054e-02,\n",
       "        7.60412365e-02, -4.29042667e-01, -2.06879869e-01, -2.84229249e-01,\n",
       "       -1.50035933e-01, -1.83060586e-01,  2.44305253e-01, -2.05348447e-01,\n",
       "       -2.09615380e-02,  5.39076984e-01, -1.07083225e-03,  3.91369343e-01,\n",
       "       -6.85549676e-02,  3.00239563e-01, -2.51639277e-01,  1.08429588e-01,\n",
       "       -1.04462802e-01,  1.14966370e-01, -8.85266364e-02,  2.53511444e-02,\n",
       "       -1.83856651e-01, -2.35181585e-01, -8.32466260e-02,  2.57542849e-01,\n",
       "       -5.50941944e-01,  5.07411174e-02,  1.54661387e-01, -1.44120440e-01,\n",
       "       -2.17895672e-01,  7.27844775e-01,  8.62608179e-02,  1.15222760e-01,\n",
       "        1.68323681e-01,  4.50208426e-01,  1.43685773e-01,  6.79301098e-02,\n",
       "        4.22192663e-02, -2.64038235e-01, -3.49467807e-02,  1.57945007e-01,\n",
       "        2.18327388e-01,  7.78679252e-02, -3.83066721e-02,  7.20502436e-02,\n",
       "       -5.20187974e-01,  1.74793601e-01,  4.12014797e-02, -2.29173422e-01,\n",
       "       -9.19151679e-02, -3.70468855e-01,  2.02227399e-01,  2.48028755e-01,\n",
       "        6.73911050e-02, -3.51485223e-01,  6.90973923e-03, -1.50028422e-01,\n",
       "       -1.31649554e-01, -9.69042350e-03,  2.77272705e-02,  3.88741165e-01,\n",
       "        2.38884047e-01, -3.27647358e-01,  1.39254287e-01,  3.01634043e-01,\n",
       "       -3.11571598e-01,  8.38105083e-02,  4.04691666e-01,  2.36611471e-01,\n",
       "        3.83163303e-01, -7.67750740e-01, -4.46781963e-01, -2.85703212e-01,\n",
       "        7.83946663e-02,  1.10321701e-01,  6.01573884e-02, -3.25588174e-02,\n",
       "        3.58305961e-01,  2.66978383e-01,  4.09545973e-02,  1.05917491e-01,\n",
       "        1.75141931e-01, -7.74486586e-02,  1.84135124e-01,  6.10432737e-02,\n",
       "        3.85491133e-01, -3.52927446e-01, -4.05098230e-01,  1.43990442e-01,\n",
       "       -7.66402110e-02,  2.20117882e-01, -4.85689938e-02,  3.74596089e-01,\n",
       "        3.06189179e-01, -2.55261272e-01,  3.21748853e-01, -8.78146514e-02,\n",
       "       -5.98290503e-01, -3.84674221e-01,  8.18791762e-02,  2.56263018e-01,\n",
       "       -9.54152942e-02, -1.63865909e-01, -1.52199969e-01,  2.63647974e-01,\n",
       "        1.63371086e-01,  4.60234545e-02, -3.15608829e-01,  2.34631106e-01,\n",
       "       -2.09340975e-01, -4.98923749e-01, -3.20952684e-01, -1.48839116e-01,\n",
       "       -3.04986387e-01, -1.08949579e-01,  5.13066828e-01,  3.53702754e-01,\n",
       "        6.21092059e-02, -5.15457094e-01, -2.00827658e-01, -1.23089097e-01,\n",
       "        1.85428023e-01, -2.32196301e-02, -1.53530031e-01,  1.27217487e-01,\n",
       "       -3.17428321e-01,  1.92535773e-01,  2.58152455e-01, -3.00820202e-01,\n",
       "       -5.28132953e-02,  3.79318707e-02, -2.27561310e-01, -5.44024259e-02,\n",
       "       -1.74044654e-01, -4.72831607e-01,  3.19920450e-01,  1.21468104e-01,\n",
       "       -1.63168177e-01, -3.23888916e-03, -2.91392654e-01,  3.83094586e-02,\n",
       "        4.62009817e-01, -7.48680020e-03,  4.30801213e-02, -8.94716382e-02,\n",
       "       -4.13325578e-01, -2.40790486e-01,  1.44402400e-01, -1.47766098e-01,\n",
       "        1.61071435e-01,  4.34380509e-02,  3.76018286e-01,  1.64695159e-01,\n",
       "       -1.54403150e-01,  3.09972584e-01,  4.80404608e-02, -1.78309083e-01,\n",
       "        4.30214256e-02, -3.38904977e-01,  2.91518513e-02,  2.63202041e-01,\n",
       "        5.55386655e-02,  7.75867179e-02, -2.05832288e-01,  8.27148631e-02,\n",
       "        3.22681293e-03,  2.07321286e-01,  4.00944352e-02, -5.59437454e-01,\n",
       "        3.47769409e-01, -4.97513711e-02, -3.64169329e-02, -4.03546959e-01,\n",
       "       -3.01966369e-02,  1.13856040e-01,  1.13030136e-01,  1.08957015e-01,\n",
       "       -2.19103023e-01, -2.31935069e-01,  9.11456067e-03, -3.47259909e-01,\n",
       "       -2.77566105e-01, -2.50209808e-01, -1.75899699e-01,  7.17897415e-02,\n",
       "       -1.83234930e-01,  4.86157648e-02, -8.92512798e-02,  4.62746322e-02,\n",
       "       -3.59634310e-01, -2.56397665e-01, -1.22282982e-01,  2.37358883e-01,\n",
       "        3.20950270e-01,  1.71291754e-01, -1.73808381e-01, -7.84538388e-02,\n",
       "       -1.48738757e-01,  3.84366423e-01,  1.41215432e+00,  2.90057436e-02,\n",
       "        2.60747522e-01,  5.46961725e-02, -2.96395868e-01,  2.70879418e-02,\n",
       "       -2.96986192e-01, -2.63844341e-01,  1.00946784e-01, -2.53455907e-01,\n",
       "       -3.97629768e-01, -2.68679768e-01,  1.84445754e-01, -9.63236317e-02,\n",
       "        2.11038709e-01, -2.16065362e-01, -2.39143014e-01,  1.33144602e-01,\n",
       "       -4.50038500e-02, -2.89866596e-01,  1.87839326e-02, -2.93318063e-01,\n",
       "        2.57934064e-01, -2.85535634e-01, -9.77079049e-02, -4.04801331e-02,\n",
       "       -5.74549437e-01,  3.14884335e-02,  1.30809307e-01, -2.83351690e-01,\n",
       "       -3.45514417e-01,  6.79959655e-02,  5.62707670e-02,  2.00932920e-01,\n",
       "        1.90236643e-01,  4.94704247e-02,  2.15851232e-01,  5.62716722e-02,\n",
       "        5.18299162e-01, -2.83536017e-01,  2.77347952e-01,  1.66273326e-01,\n",
       "       -3.61990124e-01,  5.18579595e-02,  8.81593768e-03, -3.19197208e-01,\n",
       "       -2.18995407e-01,  1.27822027e-01,  1.09256826e-01,  9.07586738e-02,\n",
       "        1.18468963e-01,  2.22544279e-02,  8.51694569e-02, -1.60095811e-01,\n",
       "        2.32340738e-01,  3.78815651e-01,  7.18764290e-02, -5.47061086e-01,\n",
       "        8.87021422e-03,  4.73444104e-01,  1.44823134e-01, -5.47532253e-02,\n",
       "        4.57963318e-01, -8.80609229e-02, -2.55462527e-01,  6.04559220e-02,\n",
       "        7.15356767e-02,  1.41310349e-01, -1.84396699e-01,  3.00962329e-01,\n",
       "       -4.68415469e-01, -1.41861305e-01, -3.97854224e-02,  2.98900932e-01,\n",
       "        9.67741981e-02, -8.55272189e-02,  4.15734500e-01, -7.54208863e-03,\n",
       "       -2.71079302e-01,  5.77428818e-01, -6.67325268e-03, -1.36541901e-02,\n",
       "        1.62365064e-01, -1.13170415e-01, -2.38076106e-01, -2.38888204e-01,\n",
       "        5.56803644e-01,  2.87906732e-02, -9.16000977e-02, -4.89127010e-01,\n",
       "        3.68376493e-01, -6.22304142e-01, -4.54201341e-01, -9.01641026e-02,\n",
       "        5.15042245e-01,  1.84175909e-01,  5.71064413e-01,  1.89897135e-01,\n",
       "        9.51264426e-02,  3.17387767e-02,  2.60310531e-01,  3.32291365e-01,\n",
       "        3.10566276e-01,  2.50681192e-01,  5.73333688e-02,  1.55261829e-02,\n",
       "       -9.90991294e-03, -9.03200209e-02,  4.93836284e-01,  4.26032729e-02,\n",
       "        2.61192113e-01, -3.58437270e-01,  9.55081955e-02,  1.27848282e-01,\n",
       "       -3.96566302e-01, -3.71307164e-01, -1.38742179e-02, -4.10263278e-02,\n",
       "       -1.83466151e-01,  2.74252027e-01,  3.39539379e-01, -5.85443854e-01,\n",
       "        2.16936782e-01,  8.40934888e-02, -7.10640475e-03,  4.46320385e-01,\n",
       "        5.69888204e-03, -2.29612648e-01, -1.79354832e-01, -1.34949043e-01,\n",
       "       -4.12520438e-01,  2.03932039e-02,  2.09893987e-01, -1.01810634e-01,\n",
       "        3.87038559e-01, -1.31573632e-01,  2.42954299e-01,  1.12971067e-02,\n",
       "        3.85767549e-01, -5.03510004e-03, -1.82867646e-01, -4.95910235e-02,\n",
       "        1.50805697e-01, -4.76887822e-02,  4.03690904e-01, -6.47354051e-02,\n",
       "        4.83660884e-02, -1.68343589e-01, -1.60496384e-01,  8.17542523e-02,\n",
       "       -3.11985344e-01, -9.13139880e-02,  8.63034800e-02, -1.83443725e-02,\n",
       "        6.70872768e-03, -1.69184320e-02,  1.68869093e-01,  4.74278778e-01,\n",
       "        1.32825002e-01, -9.95958596e-03,  5.08219004e-01, -2.40899131e-01,\n",
       "        2.30501249e-01,  1.62232623e-01,  1.35567514e-02, -1.28118262e-01,\n",
       "       -2.60211229e-01,  1.66827753e-01,  1.30367145e-01,  9.09171328e-02,\n",
       "       -3.09200585e-01,  2.22367212e-01,  1.94003686e-01,  2.61921614e-01,\n",
       "        4.90603715e-01, -9.20155179e-03, -3.48390490e-01, -1.27805993e-02,\n",
       "        1.53420269e-01,  3.36834975e-02, -4.23449248e-01,  4.20651466e-01,\n",
       "       -2.44896829e-01, -5.35044586e-03, -1.68420553e-01, -5.82875013e-02,\n",
       "       -8.31925571e-02, -1.74256749e-02, -7.30997920e-02, -9.52891186e-02,\n",
       "       -1.66908383e-01, -2.62106210e-01,  9.07063261e-02,  3.00426912e-02,\n",
       "        3.17195654e-01,  3.40962112e-02,  4.53505032e-02, -2.86927968e-01,\n",
       "        8.38009119e-02, -3.95312667e-01, -1.33086696e-01,  2.88966764e-02,\n",
       "        1.79366052e-01, -1.49425700e-01,  2.30035782e-01,  1.58309639e-01,\n",
       "        7.91785941e-02, -5.85981421e-02,  1.59666538e-01, -5.51210344e-02,\n",
       "       -9.07246098e-02, -2.54687667e-03, -8.65073800e-02, -1.10428892e-01,\n",
       "        1.91493705e-01, -3.42259914e-01,  8.64739250e-03, -2.19597980e-01,\n",
       "        1.28525838e-01, -2.12408230e-02, -1.33765921e-01, -8.71515274e-02,\n",
       "        1.52311966e-01, -1.42269894e-01, -3.05216908e-01, -7.39624128e-02,\n",
       "       -3.11183959e-01,  9.97648537e-02,  1.54492855e-01, -3.88467789e-01,\n",
       "       -1.10314280e-01, -2.10326567e-01,  4.01019782e-01,  1.02185614e-01,\n",
       "       -7.41645917e-02, -4.14206833e-03, -1.32178031e-02, -5.46878539e-02,\n",
       "        2.30612755e-01,  3.45243931e-01,  1.88475415e-01,  1.33474812e-01,\n",
       "       -4.24594641e-01,  2.09410861e-01,  1.54216111e-01, -1.32010400e-01,\n",
       "       -3.54433626e-01, -3.98941606e-01, -3.34106646e-02, -2.67314345e-01,\n",
       "       -2.52030283e-01, -1.78402975e-01, -6.30564511e-01,  1.12272836e-01,\n",
       "       -5.74627817e-02, -3.44419509e-01,  2.05527976e-01, -7.59879276e-02,\n",
       "        2.34919250e-01, -6.02541715e-02,  9.75113884e-02,  5.88660920e-03,\n",
       "       -2.27399290e-01,  1.87707245e-01,  2.88396567e-01, -3.79827410e-01,\n",
       "        2.19338298e-01,  1.92431763e-01,  6.87339380e-02,  3.32417130e-01,\n",
       "       -2.60812137e-02,  5.03086038e-02, -2.38539085e-01, -9.36636627e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word_embeddings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21635672, 0.4542396 , 0.22132626, 0.3991895 , 0.32384202,\n",
       "        0.3040914 ]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 0.2111), ('it', 0.2287), ('today', 0.4608), ('rainy', 0.7416)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 2], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances.argsort()[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 2], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello mehmet how are you today', \"I'm fine and you\", 'Today it is rainy']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nlp.Defaults.stop_words\n",
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8415c36f9348>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtop2vec\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTop2Vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTop2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'documents' is not defined"
     ]
    }
   ],
   "source": [
    "from top2vec import Top2Vec\n",
    "model = Top2Vec(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average silhouette score for 2 clusters is 0.68\n",
      "The average silhouette score for 3 clusters is 0.55\n",
      "The average silhouette score for 4 clusters is 0.50\n",
      "The average silhouette score for 5 clusters is 0.49\n",
      "The average silhouette score for 6 clusters is 0.48\n",
      "The average silhouette score for 7 clusters is 0.34\n",
      "The average silhouette score for 8 clusters is 0.28\n",
      "The average silhouette score for 9 clusters is 0.32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "\n",
    "sil_score_max = -1 #this is the minimum possible score\n",
    "\n",
    "for n_clusters in range(2,10):\n",
    "    model = KMeans(n_clusters = n_clusters, init='k-means++', max_iter=100, n_init=1)\n",
    "    labels = model.fit_predict(X)\n",
    "    sil_score = silhouette_score(X, labels)\n",
    "    print(\"The average silhouette score for %i clusters is %0.2f\" %(n_clusters,sil_score))\n",
    "    if sil_score > sil_score_max:\n",
    "        sil_score_max = sil_score\n",
    "        best_n_clusters = n_clusters\n",
    "best_n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 most similar pairs:\n",
      "A man is riding a horse. \t A man is riding a white horse on an enclosed ground. \t 0.8489\n",
      "A man is eating food. \t A man is eating a piece of bread. \t 0.7784\n",
      "A monkey is playing drums. \t Someone in a gorilla costume is playing a set of drums. \t 0.7041\n",
      "A man is eating food. \t A man is riding a horse. \t 0.3604\n",
      "A man is eating food. \t A man is riding a white horse on an enclosed ground. \t 0.3573\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('xlm-r-distilroberta-base-paraphrase-v1')\n",
    "\n",
    "sentences = ['A man is eating food.',\n",
    "          'A man is eating a piece of bread.',\n",
    "          'The girl is carrying a baby.',\n",
    "          'A man is riding a horse.',\n",
    "          'A woman is playing violin.',\n",
    "          'Two men pushed carts through the woods.',\n",
    "          'A man is riding a white horse on an enclosed ground.',\n",
    "          'A monkey is playing drums.',\n",
    "          'Someone in a gorilla costume is playing a set of drums.'\n",
    "          ]\n",
    "\n",
    "#Encode all sentences\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Compute cosine similarity between all pairs\n",
    "cos_sim = util.pytorch_cos_sim(embeddings, embeddings)\n",
    "\n",
    "#Add all pairs to a list with their cosine similarity score\n",
    "all_sentence_combinations = []\n",
    "for i in range(len(cos_sim)-1):\n",
    "    for j in range(i+1, len(cos_sim)):\n",
    "        all_sentence_combinations.append([cos_sim[i][j], i, j])\n",
    "\n",
    "#Sort list by the highest cosine similarity score\n",
    "all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "print(\"Top-5 most similar pairs:\")\n",
    "for score, i, j in all_sentence_combinations[0:5]:\n",
    "    print(\"{} \\t {} \\t {:.4f}\".format(i, j, cos_sim[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \t 6 \t 0.8489\n",
      "0 \t 1 \t 0.7784\n",
      "7 \t 8 \t 0.7041\n",
      "0 \t 3 \t 0.3604\n",
      "0 \t 6 \t 0.3573\n"
     ]
    }
   ],
   "source": [
    "for score, i, j in all_sentence_combinations[0:5]:\n",
    "    print(\"{} \\t {} \\t {:.4f}\".format(i, j, cos_sim[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cPickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d49b0eecb349>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcPickle\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# other imports required for nltk ...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cPickle'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "from os.path import exists\n",
    "# other imports required for nltk ...\n",
    "\n",
    "myfile = \"clf_NUMB.pickle\"\n",
    "\n",
    "objects = []\n",
    "with (open(myfile, \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile,))\n",
    "        except EOFError:\n",
    "            break\n",
    "#     pickle.dump(classifier, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-77bfbea073c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mobjects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopenfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopenfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfix_imports\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "myfile = \"clf_NUMB.pickle\"\n",
    "\n",
    "objects = []\n",
    "with (open(myfile, \"rb\")) as openfile:\n",
    "    data = pickle.load(openfile,fix_imports=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-540ace71016f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnormalise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\normalise\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnormalise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalisation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnormalise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_NSWs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrejoin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenize_basic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\normalise\\normalisation.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnormalise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtagger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtagify\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_digbased\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnormalise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretagify\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnormalise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_ALPHA\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrun_clfALPHA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnormalise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_NUMB\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrun_clfNUMB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnormalise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag_MISC\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtag_MISC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\normalise\\class_ALPHA.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msemi_supervised\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelPropagation\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mroman\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mromanNumeralPattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 most similar pairs:\n",
      "A man is riding a horse. \t A man is riding a white horse on an enclosed ground. \t 0.8289\n",
      "A man is eating food. \t A man is eating a piece of bread. \t 0.7977\n",
      "A monkey is playing drums. \t Someone in a gorilla costume is playing a set of drums. \t 0.6842\n",
      "A woman is playing violin. \t Someone in a gorilla costume is playing a set of drums. \t 0.3762\n",
      "A man is eating food. \t A man is riding a horse. \t 0.3545\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "\n",
    "sentences = ['A man is eating food.',\n",
    "          'A man is eating a piece of bread.',\n",
    "          'The girl is carrying a baby.',\n",
    "          'A man is riding a horse.',\n",
    "          'A woman is playing violin.',\n",
    "          'Two men pushed carts through the woods.',\n",
    "          'A man is riding a white horse on an enclosed ground.',\n",
    "          'A monkey is playing drums.',\n",
    "          'Someone in a gorilla costume is playing a set of drums.'\n",
    "          ]\n",
    "\n",
    "#Encode all sentences\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Compute cosine similarity between all pairs\n",
    "cos_sim = util.pytorch_cos_sim(embeddings, embeddings)\n",
    "\n",
    "#Add all pairs to a list with their cosine similarity score\n",
    "all_sentence_combinations = []\n",
    "for i in range(len(cos_sim)-1):\n",
    "    for j in range(i+1, len(cos_sim)):\n",
    "        all_sentence_combinations.append([cos_sim[i][j], i, j])\n",
    "\n",
    "#Sort list by the highest cosine similarity score\n",
    "all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "print(\"Top-5 most similar pairs:\")\n",
    "for score, i, j in all_sentence_combinations[0:5]:\n",
    "    print(\"{} \\t {} \\t {:.4f}\".format(sentences[i], sentences[j], cos_sim[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat sits outside \t\t The dog plays in the garden \t\t Score: 0.4579\n",
      "A man is playing guitar \t\t A woman watches TV \t\t Score: 0.1759\n",
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.9283\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "\n",
    "# Two lists of sentences\n",
    "sentences1 = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'The new movie is awesome']\n",
    "\n",
    "sentences2 = ['The dog plays in the garden',\n",
    "              'A woman watches TV',\n",
    "              'The new movie is so great']\n",
    "\n",
    "#Compute embedding for both lists\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "#Compute cosine-similarits\n",
    "cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "#Output the pairs with their score\n",
    "for i in range(len(sentences1)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i], sentences2[i], cosine_scores[i][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4579,  0.1059,  0.1447],\n",
       "        [ 0.1239,  0.1759, -0.0344],\n",
       "        [ 0.1696,  0.1313,  0.9283]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▋                                                                             | 5.09M/245M [00:20<08:03, 496kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.9283\n",
      "The cat sits outside \t\t The cat plays in the garden \t\t Score: 0.6855\n",
      "I love pasta \t\t Do you like pizza? \t\t Score: 0.5420\n",
      "I love pasta \t\t The new movie is awesome \t\t Score: 0.2629\n",
      "I love pasta \t\t The new movie is so great \t\t Score: 0.2268\n",
      "The new movie is awesome \t\t Do you like pizza? \t\t Score: 0.1885\n",
      "A man is playing guitar \t\t A woman watches TV \t\t Score: 0.1759\n",
      "The new movie is so great \t\t Do you like pizza? \t\t Score: 0.1615\n",
      "The cat plays in the garden \t\t A woman watches TV \t\t Score: 0.1521\n",
      "The cat sits outside \t\t The new movie is awesome \t\t Score: 0.1475\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "\n",
    "# Single list of sentences - Possible tens of thousands of sentences\n",
    "sentences = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'I love pasta',\n",
    "             'The new movie is awesome',\n",
    "             'The cat plays in the garden',\n",
    "             'A woman watches TV',\n",
    "             'The new movie is so great',\n",
    "             'Do you like pizza?']\n",
    "\n",
    "paraphrases = util.paraphrase_mining(model, sentences)\n",
    "\n",
    "for paraphrase in paraphrases[0:10]:\n",
    "    score, i, j = paraphrase\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences[i], sentences[j], score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A man is eating pasta.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "A man is eating food. (Score: 0.7096)\n",
      "A man is eating a piece of bread. (Score: 0.6074)\n",
      "A man is riding a horse. (Score: 0.3360)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.3069)\n",
      "A woman is playing violin. (Score: 0.2378)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Someone in a gorilla costume is playing a set of drums.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "A monkey is playing drums. (Score: 0.6842)\n",
      "A woman is playing violin. (Score: 0.3762)\n",
      "A man is riding a horse. (Score: 0.3079)\n",
      "A cheetah is running behind its prey. (Score: 0.2760)\n",
      "A man is eating a piece of bread. (Score: 0.2495)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A cheetah chases prey on across a field.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "A cheetah is running behind its prey. (Score: 0.7814)\n",
      "A monkey is playing drums. (Score: 0.2824)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.2208)\n",
      "A man is riding a horse. (Score: 0.2017)\n",
      "A man is eating food. (Score: 0.1886)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is a simple application for sentence embeddings: semantic search\n",
    "\n",
    "We have a corpus with various sentences. Then, for a given query sentence,\n",
    "we want to find the most similar sentence in this corpus.\n",
    "\n",
    "This script outputs for various queries the top 5 most similar sentences in the corpus.\n",
    "\"\"\"\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "embedder = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "\n",
    "# Corpus with example sentences\n",
    "corpus = ['A man is eating food.',\n",
    "          'A man is eating a piece of bread.',\n",
    "          'The girl is carrying a baby.',\n",
    "          'A man is riding a horse.',\n",
    "          'A woman is playing violin.',\n",
    "          'Two men pushed carts through the woods.',\n",
    "          'A man is riding a white horse on an enclosed ground.',\n",
    "          'A monkey is playing drums.',\n",
    "          'A cheetah is running behind its prey.'\n",
    "          ]\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['A man is eating pasta.', 'Someone in a gorilla costume is playing a set of drums.', 'A cheetah chases prey on across a field.']\n",
    "\n",
    "\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = min(5, len(corpus))\n",
    "for query in queries:\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        print(corpus[idx], \"(Score: {:.4f})\".format(score))\n",
    "\n",
    "    \"\"\"\n",
    "    # Alternatively, we can also use util.semantic_search to perform cosine similarty + topk\n",
    "    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=5)\n",
    "    hits = hits[0]      #Get the hits for the first query\n",
    "    for hit in hits:\n",
    "        print(corpus[hit['corpus_id']], \"(Score: {:.4f})\".format(hit['score']))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__() missing 1 required positional argument: 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-3e5548548c55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0membedder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __call__() missing 1 required positional argument: 'text'"
     ]
    }
   ],
   "source": [
    "embedder.tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f092da366059>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpytopicrank\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTopicRank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\user\\desktop\\staj dosyalarım\\virtual\\env\\lib\\site-packages\\pytopicrank\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtopicrank\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTopicRank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\user\\desktop\\staj dosyalarım\\virtual\\env\\lib\\site-packages\\pytopicrank\\topicrank.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangdetect\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdetect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhierarchy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinkage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcophenet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcluster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpdist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from pytopicrank import TopicRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sklearn) (0.24.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sklearn) (1.0.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sklearn) (1.6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sklearn) (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
